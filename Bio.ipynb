{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install Bio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACtpj1JBWEL_",
        "outputId": "2f731e4f-cc21-4366-b847-a2c707e8d916"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Bio in /usr/local/lib/python3.12/dist-packages (1.8.1)\n",
            "Requirement already satisfied: biopython>=1.80 in /usr/local/lib/python3.12/dist-packages (from Bio) (1.85)\n",
            "Requirement already satisfied: gprofiler-official in /usr/local/lib/python3.12/dist-packages (from Bio) (1.0.0)\n",
            "Requirement already satisfied: mygene in /usr/local/lib/python3.12/dist-packages (from Bio) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from Bio) (2.2.2)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.12/dist-packages (from Bio) (1.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from Bio) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from Bio) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from biopython>=1.80->Bio) (2.0.2)\n",
            "Requirement already satisfied: biothings-client>=0.2.6 in /usr/local/lib/python3.12/dist-packages (from mygene->Bio) (0.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->Bio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->Bio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->Bio) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch->Bio) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pooch->Bio) (25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->Bio) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->Bio) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->Bio) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->Bio) (2025.10.5)\n",
            "Requirement already satisfied: httpx>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from biothings-client>=0.2.6->mygene->Bio) (0.28.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->Bio) (1.17.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import Entrez, SeqIO\n",
        "import json\n",
        "import time"
      ],
      "metadata": {
        "id": "J63-rxFxWFMD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Entrez.email = \"as.mohammed@ufl.edu\""
      ],
      "metadata": {
        "id": "JE47xzKNWPLz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_order_to_superorder(order_name):\n",
        "    \"\"\"Map order to superorder\"\"\"\n",
        "    superorder_map = {\n",
        "        # Marsupials\n",
        "        'Didelphimorphia': 'Marsupials',\n",
        "        'Diprotodontia': 'Marsupials',\n",
        "        'Peramelemorphia': 'Marsupials',\n",
        "        'Dasyuromorphia': 'Marsupials',\n",
        "        # Afrotheria\n",
        "        'Proboscidea': 'Afrotheria',\n",
        "        'Sirenia': 'Afrotheria',\n",
        "        'Hyracoidea': 'Afrotheria',\n",
        "        'Tubulidentata': 'Afrotheria',\n",
        "        'Macroscelidea': 'Afrotheria',\n",
        "        'Afrosoricida': 'Afrotheria',\n",
        "        # Xenarthra\n",
        "        'Cingulata': 'Xenarthra',\n",
        "        'Pilosa': 'Xenarthra',\n",
        "        # Laurasiatheria\n",
        "        'Eulipotyphla': 'Laurasiatheria',\n",
        "        'Chiroptera': 'Laurasiatheria',\n",
        "        'Carnivora': 'Laurasiatheria',\n",
        "        'Pholidota': 'Laurasiatheria',\n",
        "        'Perissodactyla': 'Laurasiatheria',\n",
        "        'Cetartiodactyla': 'Laurasiatheria',\n",
        "        'Artiodactyla': 'Laurasiatheria',\n",
        "        # Euarchontoglires\n",
        "        'Primates': 'Euarchontoglires',\n",
        "        'Scandentia': 'Euarchontoglires',\n",
        "        'Dermoptera': 'Euarchontoglires',\n",
        "        'Rodentia': 'Euarchontoglires',\n",
        "        'Lagomorpha': 'Euarchontoglires',\n",
        "    }\n",
        "    return superorder_map.get(order_name, 'Unclassified')"
      ],
      "metadata": {
        "id": "5Skf_CkWG3Gf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_precedence(definition):\n",
        "    \"\"\"\n",
        "    Returns precedence score:\n",
        "    1 = \"alpha\" (not subunit alpha or alpha-like)\n",
        "    2 = \"subunit alpha\" (not alpha-like)\n",
        "    3 = \"subunit alpha-like\"\n",
        "    4 = other (will be filtered out)\n",
        "    \"\"\"\n",
        "    defn = definition.lower()\n",
        "\n",
        "    if \"alpha\" in defn and \"subunit alpha\" not in defn and \"alpha-like\" not in defn:\n",
        "        return 1\n",
        "    elif \"subunit alpha\" in defn and \"alpha-like\" not in defn:\n",
        "        return 2\n",
        "    elif \"subunit alpha-like\" in defn or \"alpha-like\" in defn:\n",
        "        return 3\n",
        "    else:\n",
        "        return 4\n"
      ],
      "metadata": {
        "id": "6iKvGpJaG7SQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fetching all mammalian hemoglobin alpha sequences...\")\n",
        "\n",
        "handle = Entrez.esearch(db=\"protein\",\n",
        "                        term=\"hemoglobin alpha AND Mammalia[Organism]\",\n",
        "                        retmax=5000)\n",
        "record = Entrez.read(handle)\n",
        "all_protein_ids = record['IdList']\n",
        "\n",
        "print(f\"Found {len(all_protein_ids)} sequences total\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG6kfZSbWTRw",
        "outputId": "8d6fa4b9-d64b-4308-83aa-ca91fa27efa4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching all mammalian hemoglobin alpha sequences...\n",
            "Found 5000 sequences total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences_data = []\n",
        "\n",
        "for i, protein_id in enumerate(all_protein_ids):\n",
        "    if i % 50 == 0:\n",
        "        print(f\"Processing {i}/{len(all_protein_ids)}...\")\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    try:\n",
        "        fetch_handle = Entrez.efetch(db=\"protein\", id=protein_id,\n",
        "                                     rettype=\"gb\", retmode=\"xml\")\n",
        "        fetch_records = Entrez.read(fetch_handle)\n",
        "\n",
        "        if not fetch_records:\n",
        "            continue\n",
        "\n",
        "        record_data = fetch_records[0]\n",
        "        sequence = record_data['GBSeq_sequence']\n",
        "        organism = record_data['GBSeq_organism']\n",
        "        protein_def = record_data['GBSeq_definition']\n",
        "\n",
        "\n",
        "        tax_id = None\n",
        "        if 'GBSeq_feature-table' in record_data:\n",
        "            for feature in record_data['GBSeq_feature-table']:\n",
        "                if feature['GBFeature_key'] == 'source':\n",
        "                    for qualifier in feature['GBFeature_quals']:\n",
        "                        if qualifier['GBQualifier_name'] == 'db_xref':\n",
        "                            if 'taxon' in qualifier['GBQualifier_value']:\n",
        "                                tax_id = qualifier['GBQualifier_value'].split(':')[1]\n",
        "\n",
        "\n",
        "        if tax_id:\n",
        "            tax_handle = Entrez.efetch(db=\"taxonomy\", id=tax_id, retmode=\"xml\")\n",
        "            tax_records = Entrez.read(tax_handle)\n",
        "            tax_record = tax_records[0]\n",
        "\n",
        "            lineage_dict = {}\n",
        "            for tax_level in tax_record.get('LineageEx', []):\n",
        "                lineage_dict[tax_level['Rank']] = tax_level['ScientificName']\n",
        "\n",
        "            order_name = lineage_dict.get('order', 'Unknown')\n",
        "            superorder_name = map_order_to_superorder(order_name)\n",
        "\n",
        "            sequences_data.append({\n",
        "                'protein_id': protein_id,\n",
        "                'tax_id': tax_id,\n",
        "                'species': organism,\n",
        "                'sequence': sequence,\n",
        "                'definition': protein_def,\n",
        "                'kingdom': lineage_dict.get('kingdom', 'Animalia'),\n",
        "                'phylum': lineage_dict.get('phylum', ''),\n",
        "                'class': lineage_dict.get('class', ''),\n",
        "                'order': order_name,\n",
        "                'family': lineage_dict.get('family', ''),\n",
        "                'genus': lineage_dict.get('genus', ''),\n",
        "                'seq_length': len(sequence),\n",
        "                'superorder': superorder_name\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {protein_id}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"Successfully retrieved {len(sequences_data)} sequences with taxonomy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myBDF4ysWcCh",
        "outputId": "c8ac1dd0-369a-4f4b-9efb-2d0b617e5f4b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 0/5000...\n",
            "Processing 50/5000...\n",
            "Processing 100/5000...\n",
            "Processing 150/5000...\n",
            "Processing 200/5000...\n",
            "Processing 250/5000...\n",
            "Processing 300/5000...\n",
            "Processing 350/5000...\n",
            "Processing 400/5000...\n",
            "Processing 450/5000...\n",
            "Processing 500/5000...\n",
            "Processing 550/5000...\n",
            "Processing 600/5000...\n",
            "Processing 650/5000...\n",
            "Processing 700/5000...\n",
            "Processing 750/5000...\n",
            "Processing 800/5000...\n",
            "Processing 850/5000...\n",
            "Processing 900/5000...\n",
            "Processing 950/5000...\n",
            "Processing 1000/5000...\n",
            "Processing 1050/5000...\n",
            "Processing 1100/5000...\n",
            "Processing 1150/5000...\n",
            "Processing 1200/5000...\n",
            "Processing 1250/5000...\n",
            "Processing 1300/5000...\n",
            "Processing 1350/5000...\n",
            "Processing 1400/5000...\n",
            "Processing 1450/5000...\n",
            "Processing 1500/5000...\n",
            "Processing 1550/5000...\n",
            "Processing 1600/5000...\n",
            "Processing 1650/5000...\n",
            "Processing 1700/5000...\n",
            "Processing 1750/5000...\n",
            "Processing 1800/5000...\n",
            "Processing 1850/5000...\n",
            "Processing 1900/5000...\n",
            "Processing 1950/5000...\n",
            "Processing 2000/5000...\n",
            "Processing 2050/5000...\n",
            "Processing 2100/5000...\n",
            "Processing 2150/5000...\n",
            "Processing 2200/5000...\n",
            "Processing 2250/5000...\n",
            "Processing 2300/5000...\n",
            "Processing 2350/5000...\n",
            "Processing 2400/5000...\n",
            "Processing 2450/5000...\n",
            "Processing 2500/5000...\n",
            "Processing 2550/5000...\n",
            "Processing 2600/5000...\n",
            "Processing 2650/5000...\n",
            "Processing 2700/5000...\n",
            "Processing 2750/5000...\n",
            "Processing 2800/5000...\n",
            "Processing 2850/5000...\n",
            "Processing 2900/5000...\n",
            "Processing 2950/5000...\n",
            "Processing 3000/5000...\n",
            "Processing 3050/5000...\n",
            "Processing 3100/5000...\n",
            "Processing 3150/5000...\n",
            "Processing 3200/5000...\n",
            "Processing 3250/5000...\n",
            "Processing 3300/5000...\n",
            "Processing 3350/5000...\n",
            "Processing 3400/5000...\n",
            "Processing 3450/5000...\n",
            "Processing 3500/5000...\n",
            "Processing 3550/5000...\n",
            "Processing 3600/5000...\n",
            "Processing 3650/5000...\n",
            "Processing 3700/5000...\n",
            "Processing 3750/5000...\n",
            "Processing 3800/5000...\n",
            "Processing 3850/5000...\n",
            "Processing 3900/5000...\n",
            "Processing 3950/5000...\n",
            "Processing 4000/5000...\n",
            "Processing 4050/5000...\n",
            "Processing 4100/5000...\n",
            "Processing 4150/5000...\n",
            "Processing 4200/5000...\n",
            "Processing 4250/5000...\n",
            "Processing 4300/5000...\n",
            "Processing 4350/5000...\n",
            "Processing 4400/5000...\n",
            "Processing 4450/5000...\n",
            "Processing 4500/5000...\n",
            "Processing 4550/5000...\n",
            "Processing 4600/5000...\n",
            "Processing 4650/5000...\n",
            "Processing 4700/5000...\n",
            "Processing 4750/5000...\n",
            "Processing 4800/5000...\n",
            "Processing 4850/5000...\n",
            "Processing 4900/5000...\n",
            "Processing 4950/5000...\n",
            "Successfully retrieved 5000 sequences with taxonomy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n"
      ],
      "metadata": {
        "id": "iP10ljGWZJMC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== APPLYING FILTERS ===\\n\")\n",
        "\n",
        "\n",
        "df = pd.DataFrame(sequences_data)\n",
        "\n",
        "\n",
        "df['precedence'] = df['definition'].apply(get_precedence)\n",
        "\n",
        "\n",
        "df = df[df['precedence'] <= 3].copy()\n",
        "print(f\"After filtering for alpha/subunit alpha/alpha-like: {len(df)} sequences\")\n",
        "\n",
        "\n",
        "df = df[~df['definition'].str.lower().str.contains('partial', na=False)].copy()\n",
        "print(f\"After removing partial sequences: {len(df)} sequences\")\n",
        "\n",
        "#keep sequences longer than 100 amino acids (full-length)\n",
        "df = df[df['seq_length'] > 100].copy()\n",
        "print(f\"After length filter (>100 aa): {len(df)} sequences\")\n",
        "\n",
        "df = df[df['seq_length'] < 200].copy()\n",
        "print(f\"After length filter (<200 aa): {len(df)} sequences\")\n",
        "\n",
        "\n",
        "df = df.sort_values(['species', 'precedence', 'seq_length'],\n",
        "                    ascending=[True, True, False])\n",
        "df_unique = df.drop_duplicates(subset='species', keep='first')\n",
        "\n",
        "print(f\"After deduplication (one per species): {len(df_unique)} unique species\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPoddJG7ZP1f",
        "outputId": "df290117-e71a-4ab1-8f09-d83f5e04f6a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== APPLYING FILTERS ===\n",
            "\n",
            "After filtering for alpha/subunit alpha/alpha-like: 3117 sequences\n",
            "After removing partial sequences: 3040 sequences\n",
            "After length filter (>100 aa): 2824 sequences\n",
            "After length filter (<200 aa): 2769 sequences\n",
            "After deduplication (one per species): 402 unique species\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n=== DATASET SUMMARY ===\\n\")\n",
        "print(\"Sequences per superorder:\")\n",
        "print(df_unique['superorder'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nSequences per order (top 15):\")\n",
        "print(df_unique['order'].value_counts().head(15))\n",
        "\n",
        "print(\"\\nPrecedence distribution:\")\n",
        "print(df_unique['precedence'].value_counts().sort_index())\n",
        "\n",
        "print(f\"\\nSequence length stats (amino acids):\")\n",
        "print(f\"  Min: {df_unique['seq_length'].min()}\")\n",
        "print(f\"  Max: {df_unique['seq_length'].max()}\")\n",
        "print(f\"  Mean: {df_unique['seq_length'].mean():.1f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MToRdDW7ZX7R",
        "outputId": "5e026ffe-badc-4e99-f68b-72d22988ab46"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== DATASET SUMMARY ===\n",
            "\n",
            "Sequences per superorder:\n",
            "superorder\n",
            "Afrotheria           13\n",
            "Euarchontoglires    164\n",
            "Laurasiatheria      203\n",
            "Marsupials           14\n",
            "Unclassified          4\n",
            "Xenarthra             4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sequences per order (top 15):\n",
            "order\n",
            "Rodentia          81\n",
            "Artiodactyla      72\n",
            "Carnivora         66\n",
            "Primates          65\n",
            "Chiroptera        35\n",
            "Eulipotyphla      15\n",
            "Lagomorpha        14\n",
            "Perissodactyla    13\n",
            "Diprotodontia      6\n",
            "Proboscidea        4\n",
            "Dasyuromorphia     4\n",
            "Pilosa             3\n",
            "Afrosoricida       3\n",
            "Sirenia            3\n",
            "Monotremata        3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Precedence distribution:\n",
            "precedence\n",
            "1    125\n",
            "2    269\n",
            "3      8\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sequence length stats (amino acids):\n",
            "  Min: 101\n",
            "  Max: 187\n",
            "  Mean: 138.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_unique.to_csv('hemoglobin_filtered_unique.csv', index=False)\n",
        "with open('hemoglobin_filtered_unique.json', 'w') as f:\n",
        "    json.dump(df_unique.to_dict('records'), f, indent=2)\n",
        "\n",
        "print(\"\\nSaved to hemoglobin_filtered_unique.csv and .json\")\n",
        "print(f\"\\nTotal unique species ready for stratified sampling: {len(df_unique)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEpazj9-ZYoG",
        "outputId": "0093b083-0b59-48ef-f211-8428c0ac093d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved to hemoglobin_filtered_unique.csv and .json\n",
            "\n",
            "Total unique species ready for stratified sampling: 402\n"
          ]
        }
      ]
    }
  ]
}